# CVE Database Manager

This repository contains scripts and configurations to manage a CVE database and serve the data via a FastAPI application.

## Credit

This project uses data from the [CVEProject/cvelistV5](https://github.com/CVEProject/cvelistV5) repository.

## Setup

### Prerequisites
- PostgreSQL
- Python 3.x

### Installation

1. **Clone the Repository**

   ```sh
   git clone https://github.com/iam-niranjan/cve-database-manager.git
   cd cve-database-manager

### Install Dependencies

pip install -r requirements.txt

### Clone the CVE Data Repository

```
git clone https://github.com/CVEProject/cvelistV5.git
```


### Database Schema

Create the necessary tables and views in your PostgreSQL database using the following SQL statements:

```sql
-- Table to Store CVE Files
CREATE TABLE cve_files (
    cve_id TEXT PRIMARY KEY,
    hash TEXT,
    data JSONB
);

-- View to Flatten CVE Data
CREATE VIEW cve_flat_view AS
SELECT
    cve_id,
    (data->'cveMetadata'->>'assignerOrgId') AS assigner_org_id,
    (data->'cveMetadata'->>'assignerShortName') AS assigner_short_name,
    (data->'cveMetadata'->>'requesterUserId') AS requester_user_id,
    (data->'cveMetadata'->>'serial')::INTEGER AS serial,
    (data->'cveMetadata'->>'state') AS state,
    (data->'cveMetadata'->>'dateReserved')::TIMESTAMP AS date_reserved,
    (data->'cveMetadata'->>'datePublished')::TIMESTAMP AS date_published,
    (data->'containers'->'cna'->'providerMetadata'->>'orgId') AS providerMetadata_org_id,
    (data->'containers'->'cna'->'providerMetadata'->>'shortName') AS providerMetadata_short_name,
    (data->'containers'->'cna'->'providerMetadata'->>'dateUpdated')::TIMESTAMP AS providerMetadata_date_updated,
    (data->'containers'->'cna'->>'title') AS title,
    (data->'containers'->'cna'->>'datePublic')::TIMESTAMP AS date_public,
    (data->'containers'->'cna'->>'dateAssigned')::TIMESTAMP AS date_assigned,
    (data->'containers'->'cna'->'problemTypes'->0->'descriptions'->0->>'lang') AS problem_type_lang,
    (data->'containers'->'cna'->'problemTypes'->0->'descriptions'->0->>'cweId') AS problem_type_cwe_id,
    (data->'containers'->'cna'->'problemTypes'->0->'descriptions'->0->>'description') AS problem_type_description,
    (data->'containers'->'cna'->'problemTypes'->0->'descriptions'->0->>'type') AS problem_type_type,
    (data->'containers'->'cna'->'impacts'->0->>'capecId') AS impact_capec_id,
    (data->'containers'->'cna'->'impacts'->0->'descriptions'->0->>'lang') AS impact_lang,
    (data->'containers'->'cna'->'impacts'->0->'descriptions'->0->>'value') AS impact_value,
    (data->'containers'->'cna'->'affected'->0->>'vendor') AS affected_vendor,
    (data->'containers'->'cna'->'affected'->0->>'product') AS affected_product,
    (data->'containers'->'cna'->'affected'->0->>'platforms') AS affected_platforms,
    (data->'containers'->'cna'->'affected'->0->>'collectionURL') AS affected_collection_url,
    (data->'containers'->'cna'->'affected'->0->>'packageName') AS affected_package_name,
    (data->'containers'->'cna'->'affected'->0->>'repo') AS affected_repo,
    (data->'containers'->'cna'->'affected'->0->>'modules') AS affected_modules,
    (data->'containers'->'cna'->'affected'->0->>'programFiles') AS affected_program_files,
    ARRAY(SELECT jsonb_array_elements_text((data->'containers'->'cna'->'affected'->0->>'programRoutines')::jsonb)) AS affected_program_routines,
    ARRAY(SELECT jsonb_array_elements_text((data->'containers'->'cna'->'affected'->0->>'changes')::jsonb)) AS affected_changes,
    (data->'containers'->'cna'->'affected'->0->>'versions') AS affected_versions,
    (data->'containers'->'cna'->'affected'->0->>'defaultStatus') AS affected_default_status,
    (data->'containers'->'cna'->'affected'->0->>'cpes') AS affected_cpes,
    (data->'containers'->'cna'->'descriptions'->0->>'lang') AS description_lang,
    (data->'containers'->'cna'->'descriptions'->0->>'value') AS description_value,
    (data->'containers'->'cna'->'descriptions'->0->>'supportingMedia') AS description_supporting_media,
    (data->'containers'->'cna'->'metrics'->0->>'format') AS metrics_format,
    (data->'containers'->'cna'->'metrics'->0->>'scenarios') AS metrics_scenarios,
    (data->'containers'->'cna'->'metrics'->0->>'cvssV4_0') AS metrics_cvssv4_0,
    (data->'containers'->'cna'->'metrics'->0->>'cvssV3_1') AS metrics_cvssv3_1,
    (data->'containers'->'cna'->'metrics'->0->>'cvssV3_0') AS metrics_cvssv3_0,
    (data->'containers'->'cna'->'metrics'->0->>'cvssV2_0') AS metrics_cvssv2_0,
    (data->'containers'->'cna'->'solutions'->0->>'lang') AS solutions_lang,
    (data->'containers'->'cna'->'solutions'->0->>'value') AS solutions_value,
    (data->'containers'->'cna'->'solutions'->0->>'supportingMedia') AS solutions_supporting_media,
    (data->'containers'->'cna'->'workarounds'->0->>'lang') AS workarounds_lang,
    (data->'containers'->'cna'->'workarounds'->0->>'value') AS workarounds_value,
    (data->'containers'->'cna'->'workarounds'->0->>'supportingMedia') AS workarounds_supporting_media,
    (data->'containers'->'cna'->'configurations'->0->>'lang') AS configurations_lang,
    (data->'containers'->'cna'->'configurations'->0->>'value') AS configurations_value,
    (data->'containers'->'cna'->'configurations'->0->>'supportingMedia') AS configurations_supporting_media,
    (data->'containers'->'cna'->'exploits'->0->>'lang') AS exploits_lang,
    (data->'containers'->'cna'->'exploits'->0->>'value') AS exploits_value,
    (data->'containers'->'cna'->'exploits'->0->>'supportingMedia') AS exploits_supporting_media,
    (data->'containers'->'cna'->>'timeline') AS timeline,
    (data->'containers'->'cna'->>'credits') AS credits,
    (data->'containers'->'cna'->>'references') AS references,
    (data->'containers'->'cna'->'source'->>'defects') AS source_defects,
    (data->'containers'->'cna'->'source'->>'advisory') AS source_advisory,
    (data->'containers'->'cna'->'source'->>'discovery') AS source_discovery,
    (data->'containers'->'cna'->'source'->>'other') AS source_other,
    (data->'containers'->'cna'->>'taxonomyMappings') AS taxonomy_mappings,
    (data->'containers'->'cna'->'taxonomyMappings'->0->>'taxonomyName') AS taxonomy_name,
    (data->'containers'->'cna'->'taxonomyMappings'->0->>'taxonomyVersion') AS taxonomy_version,
    ARRAY(SELECT jsonb_array_elements_text((data->'containers'->'cna'->'taxonomyMappings'->0->>'taxonomyRelations')::jsonb)) AS taxonomy_relations,
    (data->>'dataType') AS data_type,
    (data->>'dataVersion') AS data_version,
    (data->>'tags') AS tags
FROM cve_files;

-- Table to Store Hashes
CREATE TABLE file_hashes (
    cve_id TEXT PRIMARY KEY,
    hash TEXT
);
```

### Python Script to Update Database

Run the following Python script to update the database with CVE data from the local repository:

```python
import os
import json
import hashlib
import psycopg2
from psycopg2 import sql
from concurrent.futures import ThreadPoolExecutor, as_completed
from psycopg2.pool import SimpleConnectionPool
import subprocess

# PostgreSQL connection details
DB_NAME = '<DB_NAME>'
DB_USER = '<DB_USER>'
DB_PASSWORD = '<DB_PASSWORD>'
DB_HOST = '<DB_HOST>'
DB_PORT = '<DB_PORT>'

# Local repository path
LOCAL_REPO_PATH = '<LOCAL_REPO_PATH>'
CVE_DIR = os.path.join(LOCAL_REPO_PATH, 'cves')

# Connection pool
connection_pool = SimpleConnectionPool(1, 10, dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT)

# Function to calculate the hash of a file
def calculate_hash(file_path):
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        buf = f.read()
        hasher.update(buf)
    return hasher.hexdigest()

# Function to update the database with new or changed JSON files
def update_database(cve_id, file_path, file_hash):
    connection = connection_pool.getconn()
    if connection:
        cursor = connection.cursor()
        try:
            with open(file_path, 'r') as f:
                cve_data = json.load(f)

            # Check if the file has changed
            cursor.execute(sql.SQL("SELECT hash FROM file_hashes WHERE cve_id = %s"), [cve_id])
            result = cursor.fetchone()
            if result and result[0] == file_hash:
                print(f"File {cve_id} has not changed.")
            else:
                # Insert or update the file in the database
                cursor.execute(
                    sql.SQL("INSERT INTO cve_files (cve_id, hash, data) VALUES (%s, %s, %s) ON CONFLICT (cve_id) DO UPDATE SET hash = %s, data = %s"),
                    [cve_id, file_hash, json.dumps(cve_data), file_hash, json.dumps(cve_data)]
                )
                cursor.execute(
                    sql.SQL("INSERT INTO file_hashes (cve_id, hash) VALUES (%s, %s) ON CONFLICT (cve_id) DO UPDATE SET hash = %s"),
                    [cve_id, file_hash, file_hash]
                )
                connection.commit()
                print(f"File {cve_id} updated in the database.")
        except Exception as e:
            print(f"Error updating the database: {e}")
        finally:
            cursor.close()
            connection_pool.putconn(connection)

# Function to process a single file
def process_file(file_path):
    cve_id = os.path.splitext(os.path.basename(file_path))[0]  # Extract CVE ID from file name
    file_hash = calculate_hash(file_path)
    update_database(cve_id, file_path, file_hash)

# Function to pull the latest changes from the Git repository
def git_pull():
    try:
        subprocess.check_call(['git', 'pull'], cwd=LOCAL_REPO_PATH)
        print("Successfully pulled the latest changes from the Git repository.")
    except subprocess.CalledProcessError as e:
        print(f"Error pulling the latest changes from the Git repository: {e}")

# Main function to crawl the repository and update the database
def main():
    # Pull the latest changes from the Git repository
    git_pull()

    file_paths = []
    for root, dirs, files in os.walk(CVE_DIR):
        for file in files:
            if file.endswith('.json'):
                file_paths.append(os.path.join(root, file))

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(process_file, file_path) for file_path in file_paths]
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"Error processing file: {e}")

if __name__ == "__main__":
    main()
```

### FastAPI Application

Run the following FastAPI application to serve the CVE data:

```python
from fastapi import FastAPI, HTTPException, Depends, Security
from fastapi.security import APIKeyHeader
import asyncpg
import logging

app = FastAPI()

# Database connection configuration
DATABASE_CONFIG = {
    'user': '<DB_USER>',
    'password': '<DB_PASSWORD>',
    'database': '<DB_NAME>',
    'host': '<DB_HOST>',
    'port': '<DB_PORT>'
}

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Define the API key header
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

# Define the valid API key
VALID_API_KEY = "<VALID_API_KEY>"

async def get_db_connection():
    try:
        connection = await asyncpg.connect(**DATABASE_CONFIG)
        return connection
    except Exception as e:
        logger.error(f"Database connection error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Database connection error: {str(e)}")

async def get_api_key(api_key_header: str = Security(api_key_header)):
    if api_key_header == VALID_API_KEY:
        return api_key_header
    else:
        raise HTTPException(status_code=403, detail="Invalid API Key")

@app.get("/cve/{cve_id}")
async def get_cve_details(cve_id: str, api_key: str = Depends(get_api_key)):
    try:
        connection = await get_db_connection()
        query = "SELECT data FROM cve_files WHERE cve_id = \$1"
        result = await connection.fetchrow(query, cve_id)
        await connection.close()

        if result:
            return result['data']
        else:
            raise HTTPException(status_code=404, detail="CVE not found")
    except asyncpg.exceptions.UndefinedTableError:
        logger.error("Table not found")
        raise HTTPException(status_code=500, detail="Table not found")
    except asyncpg.exceptions.PostgresError as e:
        logger.error(f"Database error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")
    except Exception as e:
        logger.error(f"Error fetching CVE details: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error fetching CVE details: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### Usage

- Create the Database and Tables: Use the SQL statements in ```db_schema.sql``` to create the necessary tables and views in your PostgreSQL database.

- Update the Database: Run the ```update_cve_db.py``` script to update the database with CVE data from the local repository.

- Run the FastAPI Application: Start the FastAPI application by running ```api.py``` to serve the CVE data via the API.

